{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_PATH='./Assets/Datasets/*/'\n",
    "\n",
    "TRAINING_PATH=PARENT_PATH + 'Train/*/*'\n",
    "VALIDATION_PATH=PARENT_PATH + 'Valid/*/*'\n",
    "TEST_PATH=PARENT_PATH + 'Test/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_tf_data_train = tf.data.Dataset.list_files(TRAINING_PATH, shuffle=False)\n",
    "images_path_tf_data_valid = tf.data.Dataset.list_files(VALIDATION_PATH, shuffle=False)\n",
    "images_path_tf_data_test = tf.data.Dataset.list_files(TEST_PATH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data train: <_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n",
      "data valid: <_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n",
      "data test: <_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(f'data train: {images_path_tf_data_train}')\n",
    "print(f'data valid: {images_path_tf_data_valid}')\n",
    "print(f'data test: {images_path_tf_data_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data train: 4589\n",
      "number of data valid: 1350\n",
      "number of data test: 243\n"
     ]
    }
   ],
   "source": [
    "print(f'number of data train: {images_path_tf_data_train.cardinality()}')\n",
    "print(f'number of data valid: {images_path_tf_data_valid.cardinality()}')\n",
    "print(f'number of data test: {images_path_tf_data_test.cardinality()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_file_size(size, unit_file_size='bytes'):\n",
    "    \"\"\"Format file size to the specified unit.\"\"\"\n",
    "    units = ['bytes', 'kb', 'mb', 'gb']\n",
    "    if unit_file_size.lower() not in units:\n",
    "        raise ValueError(f\"Invalid unit. Choose from {units}.\")\n",
    "    \n",
    "    if unit_file_size.lower() == 'kb':\n",
    "        size /= 1024\n",
    "    elif unit_file_size.lower() == 'mb':\n",
    "        size /= 1024 ** 2\n",
    "    elif unit_file_size.lower() == 'gb':\n",
    "        size /= 1024 ** 3\n",
    "    \n",
    "    return f'{size:.4f}' if unit_file_size.lower() != 'bytes' else size\n",
    "\n",
    "# ==================================================== DATA TRAIN ====================================================\n",
    "def show_files_path_info(files_path_data, kind_data, is_random=False, unit_file_size='bytes'):\n",
    "    \n",
    "    idx = np.random.randint(len(files_path_data)) if is_random else 1\n",
    "\n",
    "    for file_path in files_path_data.skip(idx).take(1):\n",
    "        print('=' * 60)\n",
    "        print(' PATH INFO '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        print(f'File Path: {file_path}')\n",
    "        print()\n",
    "        \n",
    "        print('=' * 60)\n",
    "        print(' SPLIT FILE PATH '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        split_file_path = tf.strings.split(file_path, os.path.sep)\n",
    "        print(f'Split File Path: {split_file_path}')\n",
    "        print()\n",
    "        \n",
    "        print('=' * 60)\n",
    "        print(' INDEXED PATH '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        result = {value: f'Index -> {index}' for index, value in enumerate(split_file_path.numpy())}\n",
    "        for key, value in result.items():\n",
    "            print(f'{value}: {key}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(f' KIND DATA INDEX: {kind_data} '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        index = tf.where(tf.equal(split_file_path, kind_data))[0][0]\n",
    "        print(f'Index of \"{kind_data}\": {index}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' INDEX LABEL '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        index_label = index + 1\n",
    "        print(f'Index Label: {index_label}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' LABEL '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        print(f'Label: {split_file_path[index_label]}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' FILE NAME '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        file_name = split_file_path[-1].numpy().decode('utf-8')\n",
    "        print(f'File Name: {file_name}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' FILE EXTENSION '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        file_extension = os.path.splitext(file_name)[1]\n",
    "        print(f'File Extension: {file_extension}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' FILE SIZE '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        file_size = os.path.getsize(file_path.numpy().decode('utf-8'))\n",
    "        file_size = format_file_size(file_size, unit_file_size=unit_file_size)\n",
    "        print(f'File Size: {file_size} {unit_file_size}')\n",
    "        print()\n",
    "\n",
    "# ==================================================== DATA TEST ====================================================\n",
    "def show_test_files_path_info(files_path_data, is_random=False, unit_file_size='bytes'):\n",
    "    idx = np.random.randint(len(files_path_data)) if is_random else 1\n",
    "\n",
    "    for file_path in files_path_data.skip(idx).take(1):\n",
    "        print('=' * 60)\n",
    "        print(' PATH INFO '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        print(f'File Path: {file_path}')\n",
    "        print()\n",
    "        \n",
    "        print('=' * 60)\n",
    "        print(' SPLIT FILE PATH '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        split_file_path = tf.strings.split(file_path, os.path.sep)\n",
    "        print(f'Split File Path: {split_file_path}')\n",
    "        print()\n",
    "        \n",
    "        print('=' * 60)\n",
    "        print(' INDEXED PATH '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        result = {value: f'Index -> {index}' for index, value in enumerate(split_file_path.numpy())}\n",
    "        for key, value in result.items():\n",
    "            print(f'{value}: {key}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' FILE NAME '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        file_name = split_file_path[-1].numpy().decode('utf-8')\n",
    "        print(f'File Name: {file_name}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' FILE EXTENSION '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        file_extension = os.path.splitext(file_name)[1]\n",
    "        print(f'File Extension: {file_extension}')\n",
    "        print()\n",
    "\n",
    "        print('=' * 60)\n",
    "        print(' FILE SIZE '.center(60, '='))\n",
    "        print('=' * 60)\n",
    "        file_size = os.path.getsize(file_path.numpy().decode('utf-8'))\n",
    "        file_size = format_file_size(file_size, unit_file_size=unit_file_size)\n",
    "        print(f'File Size: {file_size} {unit_file_size}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "======================== PATH INFO =========================\n",
      "============================================================\n",
      "File Path: b'.\\\\Assets\\\\Datasets\\\\SIBI dataset\\\\Valid\\\\J\\\\image_J_(1685190486.500457).jpg'\n",
      "\n",
      "============================================================\n",
      "===================== SPLIT FILE PATH ======================\n",
      "============================================================\n",
      "Split File Path: [b'.' b'Assets' b'Datasets' b'SIBI dataset' b'Valid' b'J'\n",
      " b'image_J_(1685190486.500457).jpg']\n",
      "\n",
      "============================================================\n",
      "======================= INDEXED PATH =======================\n",
      "============================================================\n",
      "Index -> 0: b'.'\n",
      "Index -> 1: b'Assets'\n",
      "Index -> 2: b'Datasets'\n",
      "Index -> 3: b'SIBI dataset'\n",
      "Index -> 4: b'Valid'\n",
      "Index -> 5: b'J'\n",
      "Index -> 6: b'image_J_(1685190486.500457).jpg'\n",
      "\n",
      "============================================================\n",
      "================== KIND DATA INDEX: Valid ==================\n",
      "============================================================\n",
      "Index of \"Valid\": 4\n",
      "\n",
      "============================================================\n",
      "======================= INDEX LABEL ========================\n",
      "============================================================\n",
      "Index Label: 5\n",
      "\n",
      "============================================================\n",
      "========================== LABEL ===========================\n",
      "============================================================\n",
      "Label: b'J'\n",
      "\n",
      "============================================================\n",
      "======================== FILE NAME =========================\n",
      "============================================================\n",
      "File Name: image_J_(1685190486.500457).jpg\n",
      "\n",
      "============================================================\n",
      "====================== FILE EXTENSION ======================\n",
      "============================================================\n",
      "File Extension: .jpg\n",
      "\n",
      "============================================================\n",
      "======================== FILE SIZE =========================\n",
      "============================================================\n",
      "File Size: 8.9248 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_files_path_info(images_path_tf_data_valid, kind_data='Valid', is_random=True, unit_file_size='KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "======================== PATH INFO =========================\n",
      "============================================================\n",
      "File Path: b'.\\\\Assets\\\\Datasets\\\\SIBI dataset\\\\Test\\\\image_B_(1685775440.4310818).jpg'\n",
      "\n",
      "============================================================\n",
      "===================== SPLIT FILE PATH ======================\n",
      "============================================================\n",
      "Split File Path: [b'.' b'Assets' b'Datasets' b'SIBI dataset' b'Test'\n",
      " b'image_B_(1685775440.4310818).jpg']\n",
      "\n",
      "============================================================\n",
      "======================= INDEXED PATH =======================\n",
      "============================================================\n",
      "Index -> 0: b'.'\n",
      "Index -> 1: b'Assets'\n",
      "Index -> 2: b'Datasets'\n",
      "Index -> 3: b'SIBI dataset'\n",
      "Index -> 4: b'Test'\n",
      "Index -> 5: b'image_B_(1685775440.4310818).jpg'\n",
      "\n",
      "============================================================\n",
      "======================== FILE NAME =========================\n",
      "============================================================\n",
      "File Name: image_B_(1685775440.4310818).jpg\n",
      "\n",
      "============================================================\n",
      "====================== FILE EXTENSION ======================\n",
      "============================================================\n",
      "File Extension: .jpg\n",
      "\n",
      "============================================================\n",
      "======================== FILE SIZE =========================\n",
      "============================================================\n",
      "File Size: 15.0410 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_test_files_path_info(images_path_tf_data_test, is_random=True, unit_file_size='KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_path_to_img_tf_data(image_path, label_idx_from_path, target_size, is_gray=True):\n",
    "    split_img_path = tf.strings.split(image_path, os.path.sep)\n",
    "    label = split_img_path[label_idx_from_path]\n",
    "\n",
    "    channels = 1 if is_gray else 3 \n",
    "\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=channels) \n",
    "    image.set_shape([None, None, channels])\n",
    "    image = tf.image.resize(image, size=(target_size[0], target_size[1]))\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height=224\n",
    "new_width=224\n",
    "label_idx_from_path=5\n",
    "\n",
    "images_tf_data = images_path_tf_data.map(\n",
    "    map_func=lambda image_path: \n",
    "        convert_path_to_img_tf_data(\n",
    "            image_path=image_path, \n",
    "            label_idx_from_path=label_idx_from_path, \n",
    "            target_size=(new_height, new_width),\n",
    "            is_gray=False\n",
    "        ),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'info train data: {images_tf_data}')\n",
    "print(f'number of train data: {len(images_tf_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in images_tf_data.skip(200).take(1):\n",
    "    print(f\"{'Check Train Data'.center(61, '=')}\")\n",
    "    print(f'''    shape-image: {image.shape}\n",
    "    dtype-image: {image.dtype}\n",
    "    max-intensity: {tf.reduce_max(image)}\n",
    "    min-intensity: {tf.reduce_min(image)}\n",
    "\n",
    "    label: {label}\n",
    "    label-shape: {label.shape}\n",
    "    image-type: {label.dtype}'''\n",
    "    )\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
