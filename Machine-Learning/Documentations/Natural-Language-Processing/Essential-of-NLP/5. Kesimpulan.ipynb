{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penjelasan Dasar Natural Language Processing (NLP)\n",
    "\n",
    "Bayangkan kita sedang berbicara tentang bagaimana komputer bisa memahami dan memproses bahasa manusia, seperti Bahasa Indonesia atau Bahasa Inggris. Ini adalah bidang yang disebut **Natural Language Processing (NLP)**. Mari kita jelaskan beberapa konsep dasar yang disebutkan dalam teks tersebut dengan cara yang mudah dipahami.\n",
    "\n",
    "#### 1. Pengumpulan dan Pelabelan Data Latih\n",
    "Pertama-tama, kita perlu mengumpulkan banyak contoh teks (seperti pesan SMS) dan memberi label pada mereka. Misalnya, kita bisa mengumpulkan pesan yang berisi spam dan pesan yang tidak berisi spam.\n",
    "\n",
    "#### 2. Tokenisasi\n",
    "Tokenisasi adalah proses memecah teks menjadi kata-kata atau bagian-bagian kecil. Misalnya, kalimat \"Saya suka makan nasi\" akan dipecah menjadi [\"Saya\", \"suka\", \"makan\", \"nasi\"].\n",
    "\n",
    "#### 3. Penghapusan Kata Umum (Stop Word Removal)\n",
    "Kata-kata umum seperti \"dan\", \"di\", \"ke\" sering kali tidak memberikan banyak informasi. Jadi, kita bisa menghapusnya dari teks untuk fokus pada kata-kata yang lebih penting.\n",
    "\n",
    "#### 4. Normalisasi Huruf (Case Normalization)\n",
    "Ini adalah proses mengubah semua huruf menjadi huruf kecil atau besar agar konsisten. Misalnya, \"Saya\" dan \"saya\" dianggap sama.\n",
    "\n",
    "#### 5. Penandaan POS (POS Tagging)\n",
    "POS (Part of Speech) tagging adalah proses menandai setiap kata dengan jenis katanya, seperti kata benda, kata kerja, atau kata sifat. Misalnya, \"makan\" adalah kata kerja.\n",
    "\n",
    "#### 6. Stemming dan Lematisasi\n",
    "Stemming adalah proses mengubah kata ke bentuk dasarnya. Misalnya, \"makan\", \"memakan\", dan \"dimakan\" diubah menjadi \"makan\". Lematisasi mirip, tetapi lebih canggih karena mempertimbangkan konteks kata.\n",
    "\n",
    "#### 7. Representasi Kata sebagai Vektor\n",
    "Untuk membuat komputer bisa \"mengerti\" kata-kata, kita perlu mengubah kata-kata tersebut menjadi angka atau vektor. Ada beberapa cara untuk melakukan ini:\n",
    "\n",
    "- **Count-based Vectorization**: Menghitung berapa kali kata muncul dalam teks.\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Menghitung seberapa penting kata dalam teks berdasarkan frekuensi kemunculannya.\n",
    "\n",
    "#### 8. Word2Vec\n",
    "Word2Vec adalah metode yang lebih canggih untuk mengubah kata menjadi vektor. Metode ini menghasilkan vektor yang lebih padat dan relevan, sehingga komputer bisa memahami hubungan antar kata dengan lebih baik.\n",
    "\n",
    "#### 9. Model Pembelajaran Mendalam (Deep Learning)\n",
    "Untuk tugas seperti klasifikasi spam, kita bisa menggunakan model pembelajaran mendalam seperti **Recurrent Neural Networks (RNNs)**, terutama yang berbasis **Long Short-Term Memory (LSTM)** dan **Bi-directional LSTMs (BiLSTMs)**. Model ini sangat baik dalam memahami urutan kata dalam teks.\n",
    "\n",
    "#### Contoh Sederhana\n",
    "Bayangkan kita ingin mengajarkan komputer untuk mengenali pesan spam. Kita mulai dengan mengumpulkan banyak pesan dan memberi label apakah pesan tersebut spam atau tidak. Kemudian, kita memecah pesan menjadi kata-kata, menghapus kata-kata umum, dan mengubah kata-kata menjadi vektor. Setelah itu, kita melatih model menggunakan metode seperti TF-IDF atau Word2Vec. Akhirnya, kita menggunakan model pembelajaran mendalam untuk meningkatkan akurasi deteksi spam.\n",
    "\n",
    "Dengan cara ini, komputer bisa belajar mengenali pola dalam pesan dan memutuskan apakah pesan tersebut spam atau bukan dengan akurasi yang tinggi."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
